{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a996d864-6a89-4513-95ba-2edb457d25be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Identification de langue avec le Deep Learning et**\n",
    "## **le Bag Of World en input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb14523-04a8-424c-976a-d61585c0bbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Choix de la Tokenisation (False = BERT, True Tiktoken)\n",
    "titoken_tokenization = True\n",
    "\n",
    "## Pour résoudre les problème de mémoire et de performances\n",
    "nb_token_max = 8000\n",
    "nb_phrase_lang = 8000 # 40000\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bad4ba-8678-41a4-9008-ab1915eddae6",
   "metadata": {},
   "source": [
    "#### Lectures des phrases et de leur étiquette \"Langue\" pour les langues sélectionnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "491d66b2-90bd-49e9-99cb-9601edf52a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes de sentence.csv: 40000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lan_code</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>È occupata come Tom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Der Wissenschaftler will den Daten einen Sinn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Lo verás.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>What kind of ship is that?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tu maravillosa conferencia fue como arrojar pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1</td>\n",
       "      <td>He did not speak at all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>2</td>\n",
       "      <td>Elles partagent un élément commun.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>3</td>\n",
       "      <td>Quanto cazzo è vero!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1</td>\n",
       "      <td>Is he aware of the difficulty?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>2</td>\n",
       "      <td>Vous pouvez rester dans la chambre supplémenta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lan_code                                           sentence\n",
       "0             3                               È occupata come Tom.\n",
       "1             0  Der Wissenschaftler will den Daten einen Sinn ...\n",
       "2             4                                          Lo verás.\n",
       "3             1                         What kind of ship is that?\n",
       "4             4  Tu maravillosa conferencia fue como arrojar pe...\n",
       "...         ...                                                ...\n",
       "39995         1                           He did not speak at all.\n",
       "39996         2                 Elles partagent un élément commun.\n",
       "39997         3                               Quanto cazzo è vero!\n",
       "39998         1                     Is he aware of the difficulty?\n",
       "39999         2  Vous pouvez rester dans la chambre supplémenta...\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ouvrir le fichier d'entrée en mode lecture\n",
    "def create_lang_df(path):\n",
    "    df = pd.read_csv(path, index_col ='id')\n",
    "    return df\n",
    "\n",
    "df_big = create_lang_df('../data/multilingue/sentences.csv')\n",
    "lan_code = ['eng','fra','deu','spa','ita']\n",
    "df = pd.DataFrame(columns=df_big.columns)\n",
    "for i in range(len(lan_code)):\n",
    "    df= pd.concat([df, df_big[df_big['lan_code']==lan_code[i]].iloc[:nb_phrase_lang]])\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "n_rows = len(df)\n",
    "print('Nombre de lignes de sentence.csv:',n_rows)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "df['lan_code'] = encoder.fit_transform(df['lan_code'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71dc774-4916-4658-b015-01594a8d003b",
   "metadata": {},
   "source": [
    "#### Réalisation d'un jeu de données d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dbac26f-2f26-4e3e-9685-1aa5914569b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lan_code</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Generalmente agli studenti piace un insegnante che capisce i loro problemi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>All unsere Versuche sind fehlgeschlagen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>¿Es suficiente con 10 mil yenes?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Tom couldn't possibly have done what you claimed he did.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Tom courut à la porte.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>3</td>\n",
       "      <td>Nancy è la più bella delle quattro ragazze.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>4</td>\n",
       "      <td>¿Quién es este?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>1</td>\n",
       "      <td>The car was carrying 4 people when it had the accident.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>2</td>\n",
       "      <td>Je crains de ne pas être disponible.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>2</td>\n",
       "      <td>Tom a lavé le linge.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lan_code  \\\n",
       "0             3   \n",
       "1             0   \n",
       "2             4   \n",
       "3             1   \n",
       "4             2   \n",
       "...         ...   \n",
       "27995         3   \n",
       "27996         4   \n",
       "27997         1   \n",
       "27998         2   \n",
       "27999         2   \n",
       "\n",
       "                                                                          sentence  \n",
       "0      Generalmente agli studenti piace un insegnante che capisce i loro problemi.  \n",
       "1                                         All unsere Versuche sind fehlgeschlagen.  \n",
       "2                                                 ¿Es suficiente con 10 mil yenes?  \n",
       "3                         Tom couldn't possibly have done what you claimed he did.  \n",
       "4                                                           Tom courut à la porte.  \n",
       "...                                                                            ...  \n",
       "27995                                  Nancy è la più bella delle quattro ragazze.  \n",
       "27996                                                              ¿Quién es este?  \n",
       "27997                      The car was carrying 4 people when it had the accident.  \n",
       "27998                                         Je crains de ne pas être disponible.  \n",
       "27999                                                         Tom a lavé le linge.  \n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[5548, 5601, 5605, 5619, 5627]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# créer 2 dataframes: 1 train (70% des phrases) et 1 test (30% des phrases)\n",
    "n_train = int(n_rows*0.7)\n",
    "df_train = df.iloc[:n_train].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_test = df.iloc[n_train:].sample(frac=1, random_state=24).reset_index(drop=True)\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "display(df_train)\n",
    "nb_phrases_lang =[]\n",
    "for l in range(len(lan_code)):\n",
    "    nb_phrases_lang.append(sum(df_train['lan_code']==l))\n",
    "nb_phrases_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78bb348-f3c0-4455-b39e-a0b26527556a",
   "metadata": {},
   "source": [
    "#### Selection du tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce260244-a177-43b5-accf-0564548c2fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selection du tokenizer\n",
    "if titoken_tokenization:\n",
    "    import tiktoken\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "else:\n",
    "    from transformers import BertTokenizerFast\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb9b00-6cc3-47bc-afcf-b00fdef8738b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Tokenisation des données sélectionnées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df235a48-3ea5-47a7-af0a-f91fd20af84e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tokens avant plafonnement: 19900\n",
      "Nombre de tokens après plafonnement: 8000\n",
      "Liste des 50 tokens les plus fréquents: ['.', ',', ' a', '?', ' de', ' la', ' que', 'Tom', ' un', ' the', ' in', 'I', ' to', \"'\", ' le', 'i', ' es', ' en', 'é', ' l', ' ist', '!', 'Ich', ' Tom', ' me', 'o', ' pas', 'Je', ' di', ' nicht', ' is', ' à', ' you', ' el', ' d', 'a', ' una', ' die', 'en', ' est', ' ne', ' se', ' of', ' no', ' è', ' du', '¿', \"'t\", ' der', ' n']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "def save_dict_token(dict_ids):\n",
    "    with open('../data/dict_token', 'wb') as fichier:\n",
    "        pickle.dump(dict_ids, fichier)\n",
    "\n",
    "def load_dict_token():\n",
    "    with open('../data/dict_token', 'rb') as fichier:\n",
    "        dict_ids = pickle.load(fichier)\n",
    "        # Définition d'une liste 'écrite' des tokens\n",
    "        decoded_keys = [tokenizer.decode([key]) for key in list(dict_ids.keys())]\n",
    "    return dict_ids, decoded_keys\n",
    "\n",
    "# Création d'un dictionnaire de complet des Token ID à partir des phrases selectionnée\n",
    "dict_ids = Counter(token for ligne in df['sentence'] for token in tokenizer.encode(ligne))\n",
    "\n",
    "# Tri des token en fonction de leur fréquence\n",
    "dict_ids= sorted(dict_ids.items(), key=lambda x: x[1], reverse=True) \n",
    "print(\"Nombre de tokens avant plafonnement:\",len(dict_ids))\n",
    "print(\"Nombre de tokens après plafonnement:\",min(len(dict_ids),nb_token_max))\n",
    "\n",
    "# Limitation du nombre de token\n",
    "dict_ids = dict(dict_ids[:nb_token_max])\n",
    "# save_dict_token(dict_ids)\n",
    "\n",
    "# Définition d'une liste 'écrite' des tokens\n",
    "decoded_keys = [tokenizer.decode([key]) for key in list(dict_ids.keys())]\n",
    "print(\"Liste des 50 tokens les plus fréquents:\",decoded_keys[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adba3da-befd-44cd-a602-13b87cb664e6",
   "metadata": {},
   "source": [
    "#### Création d'un Bag Of Worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582329fa-fe9a-4e42-bc24-5349be9f0445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Créez un DataFrame BOW avec les phrases (lignes) et les fréquences de chaque token (colonnes)\n",
    "def create_BOW(data):\n",
    "    BOW = []\n",
    "    for ligne in data:\n",
    "        l_tokenised = tokenizer.encode(ligne)\n",
    "        BOW.append([l_tokenised.count(token) for token in dict_ids])\n",
    "    BOW = np.array(BOW).astype(float)\n",
    "    return BOW\n",
    "            \n",
    "X_train = create_BOW(df_train['sentence'])\n",
    "y_train = np.array(df_train['lan_code'].values.tolist())\n",
    "\n",
    "#\n",
    "X_test = create_BOW(df_test['sentence'])\n",
    "y_test = np.array(df_test['lan_code'].values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "370627b8-8c5d-4fa7-9166-6515370f496a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs = Input(shape = (nb_token_max), name = \"Input\")\n",
    "\n",
    "dense1 = Dense(units = (nb_token_max), activation = \"tanh\", kernel_initializer='glorot_uniform', name = \"Dense_1\")\n",
    "dense2 = Dense(units = nb_token_max, activation = \"tanh\", kernel_initializer='glorot_uniform', name = \"Dense_2\")\n",
    "dense3 = Dense(units = (nb_token_max/2), activation = \"tanh\", kernel_initializer='glorot_uniform', name = \"Dense_3\")\n",
    "dense4 = Dense(units = (nb_token_max/4), activation = \"tanh\", kernel_initializer='glorot_uniform', name = \"Dense_4\")\n",
    "dense5 = Dense(units = len(lan_code), activation = \"softmax\", kernel_initializer='glorot_uniform', name = \"Dense_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe68aee5-3fc8-4144-85f2-2bd9b6a92adc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x=dense1(inputs)\n",
    "x=dense2(x)\n",
    "x=dense3(x)\n",
    "x=dense4(x)\n",
    "outputs=dense5(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2b96cf3-5106-4a31-a71b-b4bffce3e0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 8000)]            0         \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 8000)              64008000  \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 8000)              64008000  \n",
      "                                                                 \n",
      " Dense_3 (Dense)             (None, 4000)              32004000  \n",
      "                                                                 \n",
      " Dense_4 (Dense)             (None, 2000)              8002000   \n",
      "                                                                 \n",
      " Dense_5 (Dense)             (None, 5)                 10005     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,032,005\n",
      "Trainable params: 168,032,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2c2b3ad-b45d-4257-883c-ab0c785ea099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.optimizers import Adam\n",
    "# optimizer = Adam(learning_rate=0.0000000001)\n",
    "\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18619756-298a-4179-861b-e4e5c0e6d3bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "394/394 [==============================] - 13s 31ms/step - loss: 0.3006 - accuracy: 0.9568 - val_loss: 0.0815 - val_accuracy: 0.9779\n",
      "Epoch 2/50\n",
      "394/394 [==============================] - 12s 30ms/step - loss: 0.0310 - accuracy: 0.9918 - val_loss: 0.0433 - val_accuracy: 0.9904\n",
      "Epoch 3/50\n",
      "394/394 [==============================] - 12s 30ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.0387 - val_accuracy: 0.9925\n",
      "Epoch 4/50\n",
      "394/394 [==============================] - 12s 30ms/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 0.0558 - val_accuracy: 0.9893\n",
      "Epoch 5/50\n",
      "394/394 [==============================] - 12s 30ms/step - loss: 0.0151 - accuracy: 0.9964 - val_loss: 0.0770 - val_accuracy: 0.9889\n",
      "Epoch 6/50\n",
      "394/394 [==============================] - 12s 30ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.0860 - val_accuracy: 0.9861\n",
      "Epoch 7/50\n",
      "394/394 [==============================] - 12s 30ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0958 - val_accuracy: 0.9893\n",
      "Epoch 8/50\n",
      "394/394 [==============================] - 12s 30ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 0.0855 - val_accuracy: 0.9900\n",
      "Epoch 9/50\n",
      "394/394 [==============================] - 12s 30ms/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.0850 - val_accuracy: 0.9907\n",
      "Epoch 10/50\n",
      "394/394 [==============================] - 12s 30ms/step - loss: 0.0164 - accuracy: 0.9966 - val_loss: 0.0818 - val_accuracy: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d21ca17c10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)\n",
    "model.fit(X_train,y_train,epochs=50,batch_size=64,validation_split=0.1, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7d6f06e-be00-40fe-a14a-b111c9426fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(X_test[:50000])\n",
    "\n",
    "\n",
    "y_test_class = y_test[:50000]\n",
    "y_pred_class = np.argmax(test_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6f577a3-0937-43cd-b180-9e761778b7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 80ms/step - loss: 0.0969 - accuracy: 0.9900\n",
      "Test Loss: 0.09691806137561798, Test Accuracy: 0.9900000095367432\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test[:100], y_test[:100])\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2122dc54-ac0e-42da-95e1-cb5cb5c4d839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2452\n",
      "           1       0.99      1.00      0.99      2399\n",
      "           2       0.99      0.98      0.98      2395\n",
      "           3       0.99      0.97      0.98      2381\n",
      "           4       0.96      0.99      0.97      2373\n",
      "\n",
      "    accuracy                           0.98     12000\n",
      "   macro avg       0.98      0.98      0.98     12000\n",
      "weighted avg       0.98      0.98      0.98     12000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classe prédite</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classe réelle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2441</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2389</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2336</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2309</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classe prédite     0     1     2     3     4\n",
       "Classe réelle                               \n",
       "0               2441     4     2     3     2\n",
       "1                  3  2389     0     2     5\n",
       "2                  3    20  2336     7    29\n",
       "3                  8     3    10  2309    51\n",
       "4                  9     8     5    11  2340"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Classifier = 0.985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "display(pd.crosstab(y_test_class,y_pred_class,rownames=['Classe réelle'], colnames=['Classe prédite']))\n",
    "accuracy_clf = accuracy_score(y_test_class,y_pred_class)\n",
    "print(\"Accuracy Classifier = {:.3f}\".format(accuracy_clf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
