{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a996d864-6a89-4513-95ba-2edb457d25be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Identification de langue avec le Deep Learning et**\n",
    "## **un embedding en input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb14523-04a8-424c-976a-d61585c0bbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import joblib\n",
    "import pickle\n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Choix de la Tokenisation (1 = Keras, 2 = BERT, 3 = Tiktoken)\n",
    "sel_tokenization = 3\n",
    "\n",
    "## Pour résoudre les problème de mémoire et de performances\n",
    "max_length = 500\n",
    "# nb_phrase_lang = 100000\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bad4ba-8678-41a4-9008-ab1915eddae6",
   "metadata": {},
   "source": [
    "#### **Lectures des phrases et de leur étiquette \"Langue\" pour les langues sélectionnées**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "491d66b2-90bd-49e9-99cb-9601edf52a57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes de sentence.csv: 1750000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lan_code</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spa</td>\n",
       "      <td>El poeta intentó suicidarse en su estudio.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fra</td>\n",
       "      <td>Je me suis sentie un peu prise de vertige.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deu</td>\n",
       "      <td>Ich reise im kommenden Jahr nach Rio.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ita</td>\n",
       "      <td>Spero che verrete alla mia festa di compleanno.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ita</td>\n",
       "      <td>La telefonata era un trucco per farlo uscire d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749995</th>\n",
       "      <td>eng</td>\n",
       "      <td>What a strange message! There is no sender and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749996</th>\n",
       "      <td>ita</td>\n",
       "      <td>Noi ci stiamo per fare una doccia.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749997</th>\n",
       "      <td>eng</td>\n",
       "      <td>Two girls were hanging on to Tom's arms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749998</th>\n",
       "      <td>fra</td>\n",
       "      <td>Tu dois cesser de t'énerver après des choses q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749999</th>\n",
       "      <td>eng</td>\n",
       "      <td>What a beautiful flower this is!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1750000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lan_code                                           sentence\n",
       "0            spa         El poeta intentó suicidarse en su estudio.\n",
       "1            fra         Je me suis sentie un peu prise de vertige.\n",
       "2            deu              Ich reise im kommenden Jahr nach Rio.\n",
       "3            ita    Spero che verrete alla mia festa di compleanno.\n",
       "4            ita  La telefonata era un trucco per farlo uscire d...\n",
       "...          ...                                                ...\n",
       "1749995      eng  What a strange message! There is no sender and...\n",
       "1749996      ita                 Noi ci stiamo per fare una doccia.\n",
       "1749997      eng           Two girls were hanging on to Tom's arms.\n",
       "1749998      fra  Tu dois cesser de t'énerver après des choses q...\n",
       "1749999      eng                   What a beautiful flower this is!\n",
       "\n",
       "[1750000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ouvrir le fichier d'entrée en mode lecture\n",
    "def create_lang_df(path):\n",
    "    df = pd.read_csv(path, index_col ='id')\n",
    "    return df\n",
    "\n",
    "df_big = create_lang_df('../data/multilingue/sentences.csv')\n",
    "lan_code = ['eng','fra','deu','spa','ita']\n",
    "df = pd.DataFrame(columns=df_big.columns)\n",
    "for i in range(len(lan_code)):\n",
    "    df= pd.concat([df, df_big[df_big['lan_code']==lan_code[i]]]) #.iloc[:nb_phrase_lang]])\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "n_rows = len(df)\n",
    "print('Nombre de lignes de sentence.csv:',n_rows)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71dc774-4916-4658-b015-01594a8d003b",
   "metadata": {},
   "source": [
    "#### **Réalisation d'un jeu de données d'entrainement et de test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dbac26f-2f26-4e3e-9685-1aa5914569b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de phrases par langue dans l'ensemble Train : [244836, 245461, 244737, 244903, 245063]\n"
     ]
    }
   ],
   "source": [
    "# créer 2 dataframes: 1 train (70% des phrases) et 1 test (30% des phrases)\n",
    "n_train = int(n_rows*0.7)\n",
    "df_train = df.iloc[:n_train].sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_test = df.iloc[n_train:].sample(frac=1, random_state=24).reset_index(drop=True)\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "# display(df_train)\n",
    "\n",
    "nb_phrases_lang =[]\n",
    "for l in lan_code: # range(len(lan_code)):\n",
    "    nb_phrases_lang.append(sum(df_train['lan_code']==l))\n",
    "print(\"Nombre de phrases par langue dans l'ensemble Train :\",nb_phrases_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e81019-c0bb-4ea0-b4f9-c046cbfa93df",
   "metadata": {},
   "source": [
    "#### **Selection du Tokenizer,**\n",
    "#### **Encodage et padding du text avec le tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e39d9e7-a9fe-4b0f-86e0-fb40cca62c20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Selection du tokenizer\n",
    "if sel_tokenization==3:\n",
    "    import tiktoken\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "elif sel_tokenization==2:\n",
    "    from transformers import BertTokenizerFast\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-uncased')\n",
    "else:\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(df['sentence'])\n",
    "\n",
    "# Données d'exemple (textes et leurs langues correspondantes)\n",
    "textes = df_train['sentence']    \n",
    "langues = df_train['lan_code']\n",
    "    \n",
    "# Encodage des étiquettes (langues)\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(langues)\n",
    "    \n",
    "def encode_text(textes):\n",
    "    global max_length, nb_unique_tokens\n",
    "    \n",
    "    if sel_tokenization==3:\n",
    "        sequences = tokenizer.encode_batch(textes)\n",
    "        nb_unique_tokens = tokenizer.max_token_value + 1\n",
    "    elif sel_tokenization==2:\n",
    "        textes = textes.tolist()\n",
    "        sequences = tokenizer.batch_encode_plus(textes).input_ids\n",
    "        nb_unique_tokens = len(set(tokenizer.get_vocab()))\n",
    "    else:\n",
    "        sequences = tokenizer.texts_to_sequences(textes)\n",
    "        nb_unique_tokens = len(tokenizer.word_index)\n",
    "    return pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229d4ea-7d97-4cf7-934a-667ee8d9fa3a",
   "metadata": {},
   "source": [
    "#### **Definition du modèle d'identification et encodage de l'ensemble Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f486b0b-5289-4cbb-96d5-b4b22fb664ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de tokens uniques : 100277\n",
      "======\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 200)          20055400  \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 200)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " Dense_1 (Dense)             (None, 400)               80400     \n",
      "                                                                 \n",
      " Dense_2 (Dense)             (None, 200)               80200     \n",
      "                                                                 \n",
      " Dense_3 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " Dense_4 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,241,405\n",
      "Trainable params: 20,241,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Padding des séquences\n",
    "padded_sequences = encode_text(textes) # pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "print(\"Nombre de tokens uniques :\",nb_unique_tokens)\n",
    "print(\"======\")\n",
    "    \n",
    "# Conversion des étiquettes en catégories one-hot\n",
    "labels_one_hot = to_categorical(labels_encoded)\n",
    "\n",
    "# Création du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=nb_unique_tokens, output_dim=200, input_length=max_length))\n",
    "model.add(GlobalAveragePooling1D())  \n",
    "model.add(Dense(units = 400, activation = \"tanh\", kernel_initializer='glorot_uniform', name = \"Dense_1\"))\n",
    "model.add(Dense(units = 200, activation = \"tanh\", kernel_initializer='glorot_uniform', name = \"Dense_2\"))\n",
    "model.add(Dense(units = 100, activation = \"tanh\", kernel_initializer='glorot_uniform', name = \"Dense_3\"))\n",
    "model.add(Dense(units = 50, activation = \"tanh\", kernel_initializer='glorot_uniform', name = \"Dense_4\"))\n",
    "\n",
    "# model.add(LSTM(100))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ed62a-02dc-4739-a112-bff0587ab4a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Entraînement du modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d06717-b28d-4ab7-8e23-26cc2c4f16a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Entraînement du modèle\n",
    "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)\n",
    "model.fit(padded_sequences, labels_one_hot, epochs=20, validation_split=0.1, batch_size=128, verbose=1, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02af7fc0-07a7-480e-a55a-7ae5a06a426b",
   "metadata": {},
   "source": [
    "#### **Sauvegarde et/ou Chargement du modele**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ad6635-e2a5-4cc0-b809-c2f6d85b4ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# definition du nom de fichier de sauvegarde\n",
    "def get_file_name(sel_tokenization):\n",
    "    if sel_tokenization == 3: return(\"../data/dl_tiktoken_id_language_model.h5\")\n",
    "    elif sel_tokenization == 2: return(\"../data/dl_BERT_id_language_model.h5\")\n",
    "    else: return(\"../data/dl_default_id_language_model.h5\")\n",
    "\n",
    "\n",
    "# Sauvegarde du modèle entrainé\n",
    "# model.save(get_file_name(sel_tokenization))\n",
    "# if sel_tokenization==1:\n",
    "#     with open('../data/tokenizer_Keras.pkl', 'wb') as tokenizer_file:\n",
    "#         pickle.dump(tokenizer, tokenizer_file)\n",
    "\n",
    "# Chargement d'un modèle pré-entrainé\n",
    "# model = keras.models.load_model(get_file_name(sel_tokenization))\n",
    "# if sel_tokenization==1:\n",
    "#     with open('../data/tokenizer_Keras.pkl', 'rb') as tokenizer_file:\n",
    "#         tokenizer = pickle.load(tokenizer_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6457401a-49ae-4fda-b025-3d0b68994253",
   "metadata": {},
   "source": [
    "#### **Test de l'efficacité du modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b38164-7529-4227-9409-c2daa5ed22ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16407/16407 [==============================] - 14s 863us/step\n",
      "======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         deu       1.00      1.00      1.00    105263\n",
      "         eng       1.00      1.00      1.00    105164\n",
      "         fra       1.00      1.00      1.00    104539\n",
      "         ita       1.00      1.00      1.00    104937\n",
      "         spa       1.00      1.00      1.00    105097\n",
      "\n",
      "    accuracy                           1.00    525000\n",
      "   macro avg       1.00      1.00      1.00    525000\n",
      "weighted avg       1.00      1.00      1.00    525000\n",
      "\n",
      "======\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classe prédite</th>\n",
       "      <th>deu</th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>ita</th>\n",
       "      <th>spa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classe réelle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deu</th>\n",
       "      <td>105158</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eng</th>\n",
       "      <td>6</td>\n",
       "      <td>105129</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fra</th>\n",
       "      <td>4</td>\n",
       "      <td>102</td>\n",
       "      <td>104356</td>\n",
       "      <td>26</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ita</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>23</td>\n",
       "      <td>104720</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spa</th>\n",
       "      <td>6</td>\n",
       "      <td>83</td>\n",
       "      <td>21</td>\n",
       "      <td>177</td>\n",
       "      <td>104810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classe prédite     deu     eng     fra     ita     spa\n",
       "Classe réelle                                         \n",
       "deu             105158      69      10      17       9\n",
       "eng                  6  105129       7      12      10\n",
       "fra                  4     102  104356      26      51\n",
       "ita                  5      67      23  104720     122\n",
       "spa                  6      83      21     177  104810"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Classifier = 0.998\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "import random\n",
    "\n",
    "# Préparation des nouvelles données à prédire\n",
    "textes_test = df_test['sentence']\n",
    "langues_test = df_test['lan_code']\n",
    "\n",
    "# Prédiction des langues des nouveaux textes\n",
    "predictions = model.predict(encode_text(textes_test))\n",
    "\n",
    "# Décodage des prédictions en langues\n",
    "predicted_labels_encoded = np.argmax(predictions, axis=1)\n",
    "predicted_languages = label_encoder.classes_[predicted_labels_encoded]\n",
    "print(\"======\")\n",
    "\n",
    "print(classification_report(langues_test,predicted_languages))\n",
    "print(\"======\")\n",
    "\n",
    "display(pd.crosstab(langues_test,predicted_languages,rownames=['Classe réelle'], colnames=['Classe prédite']))\n",
    "accuracy_clf = accuracy_score(langues_test,predicted_languages)\n",
    "print(\"Accuracy Classifier = {:.3f}\".format(accuracy_clf))\n",
    "print(\"======\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19f2f2d-9b2b-4dbf-8df3-57b45cf2918d",
   "metadata": {},
   "source": [
    "#### **Affichage d'exemples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "683d531f-fdf1-4e6d-bb23-c583ca89f3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de prédiction de langue:\n",
      "Réelle\t- Prédite - Texte\n",
      " spa\t- spa     -'Tom abrió la canilla....................................................................................................'\n",
      " fra\t- fra     -'C'est une nouveauté.....................................................................................................'\n",
      " fra\t- fra     -'Je me souviens de lorsque j'avais à peu près ton âge....................................................................'\n",
      " deu\t- deu     -'Sie haben in Ihrem Zimmer Kerzen angezündet.............................................................................'\n",
      " fra\t- fra     -'Vous avez eu plusieurs occasions de parler anglais......................................................................'\n",
      " eng\t- eng     -'Tom doesn't want to be seen talking to you..............................................................................'\n",
      " deu\t- deu     -'Wir durchkämmten die Polizeiaufzeichnungen des Vorfalls, fanden aber keine Erwähnung von Zeugen, die einen großen, bärti'\n",
      " eng\t- eng     -'If you don't eat fast, you will be late for school......................................................................'\n",
      " eng\t- eng     -'I wrote down where I was working........................................................................................'\n",
      " fra\t- fra     -'J'élève ton beau lapin..................................................................................................'\n"
     ]
    }
   ],
   "source": [
    "# Affichage des prédictions\n",
    "print(\"Exemples de prédiction de langue:\")\n",
    "print(\"Réelle\\t- Prédite - Texte\")\n",
    "n_test = min(len(textes_test),10)\n",
    "for _ in range(n_test):\n",
    "    i = random.randint(0, len(textes_test))\n",
    "    print(f\" {langues_test[i]}\\t- {predicted_languages[i]}     -'{textes_test[i].ljust(120, '.')[:120]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "869fd798-514f-49e4-8253-21a7b519da9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de mauvaises prédictions de langue:\n",
      "Réelle\t- Prédite - Texte\n",
      " spa\t- ita     -'Le di carne a mi perro..................................................................................................'\n",
      " fra\t- ita     -'Tire la chevillette, la bobinette cherra................................................................................'\n",
      " deu\t- ita     -'Oder?...................................................................................................................'\n",
      " ita\t- spa     -'Poco importa............................................................................................................'\n",
      " spa\t- ita     -'Mary calza un 37........................................................................................................'\n",
      " fra\t- eng     -'Exactement..............................................................................................................'\n",
      " spa\t- ita     -'Tu madre come mierda....................................................................................................'\n",
      " ita\t- spa     -'Prepara le coperte......................................................................................................'\n",
      " spa\t- ita     -'Tom odia a la gente.....................................................................................................'\n",
      " ita\t- eng     -'Tom guida...............................................................................................................'\n"
     ]
    }
   ],
   "source": [
    "# Affichage de mauvaises prédictions\n",
    "print(\"Exemples de mauvaises prédictions de langue:\")\n",
    "list_bad = []\n",
    "n = len(textes_test)\n",
    "if n>0:\n",
    "    for i in range(n):\n",
    "        if predicted_languages[i] != langues_test[i] :\n",
    "            list_bad.append(i)\n",
    "    print(\"Réelle\\t- Prédite - Texte\")\n",
    "    n_test = min(n,10)\n",
    "    for _ in range(n_test):\n",
    "        i = random.randint(0, len(list_bad))\n",
    "        print(f\" {langues_test[list_bad[i]]}\\t- {predicted_languages[list_bad[i]]}     -'{textes_test[list_bad[i]].ljust(120, '.')[:120]}'\")\n",
    "else:\n",
    "    print(\"Félicitations !!!! Le modèle n'a fait aucune mauvaise prédictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15894c2-563d-4e9a-913d-6caa43ae1100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
